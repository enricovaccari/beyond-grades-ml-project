{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5c37efe",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>NOTEBOOK 3 - Data Splitting\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ebb1ea",
   "metadata": {},
   "source": [
    "---\n",
    "># 1 - IMPORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdcecc1",
   "metadata": {},
   "source": [
    "### 1.1 - SETUP PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d91a6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports ready: pd, np, sns, plt, joblib, sklearn, etc.\n",
      "PROJECT_ROOT: C:\\Users\\Vaccari\\Desktop\\iCloudDrive\\Desktop\\ENRICO\\05_LEARNING\\University\\ToU\\Phases\\02_Calibration_Phase\\Applied_Machine_Learning\\Regression\\beyond-grades-ml-project\n"
     ]
    }
   ],
   "source": [
    "# Centralized setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Make sure PROJECT_PATH is in sys\n",
    "PROJECT_ROOT = Path.cwd().resolve().parent\n",
    "PROJECT_PATH = PROJECT_ROOT / \"src\" / \"project\"\n",
    "\n",
    "if str(PROJECT_PATH) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_PATH))\n",
    "\n",
    "# Centralized import\n",
    "from imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1474e353",
   "metadata": {},
   "source": [
    "---\n",
    "># 2 - DATASET LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb9bab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.1 - LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a0590af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../data/interim/01_dataset_structural_cleanup.xlsx\"\n",
    "try:\n",
    "    df = utils.load_student_dataset(dataset_path)\n",
    "    print('Data loaded successfully.')\n",
    "except Exception as e:\n",
    "    print(f'An error occurred during data loading: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f874b7",
   "metadata": {},
   "source": [
    "---\n",
    "># 3 - DATA SPLIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e8c866",
   "metadata": {},
   "source": [
    "### 3.1 - SPLITTING WITH STRATIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd714b2",
   "metadata": {},
   "source": [
    "This notebook is all about splitting the data into two groups: a **training** and a **test set**. \n",
    "- The train (or training) set will be used for EDA and modeling and will consist of 80% of the data points;\n",
    "- The test set will first be transformed according to training preprocessing statistical operations. Also, it will act as unseen data and will be used to evaluate the final model. \n",
    "\n",
    "Below I have created new dataframes:\n",
    "- `X_train`: features used for training;\n",
    "- `X_test`: target used for training;\n",
    "- `y_train`: features used for evaluation;\n",
    "- `y_test`: target used for evaluation.\n",
    "\n",
    "**Method**  \n",
    "- **Target**: 'GPA'  \n",
    "- **Stratification**: quantile-based bins (up to 5 bins via 'max_q=5') to balance 'GPA' across splits.  \n",
    "- **Function**: 'splitting.safe_train_test_split'  \n",
    "- **Test size**: 0.20  \n",
    "- **Random seed**: 42  \n",
    "- **Leakage prevention**: split was done **before** any preprocessing or target leakage-prone steps.  \n",
    "- **Saved metadata**: we persist the **bin edges**, **random seed**, **indices** for each fold/partition, and key parameters.\n",
    "\n",
    "**Why stratified by quantiles?**  \n",
    "'GPA' is continuous; quantile bins approximate stratification used for classification. This keeps the **distribution** of 'GPA' comparable between train and test.\n",
    "\n",
    "**Artifacts saved**  \n",
    "- Train/test **indices** (to re-index any future versions of the dataset).  \n",
    "- **bin_edges** used for stratification.  \n",
    "- Split **parameters** (test_size, random_state, max_q).  \n",
    "- Optional **hash** of the rows used to detect data drifts that could break reproducibility.\n",
    "\n",
    "**Checks performed**  \n",
    "- Count per quantile bin in train vs test (using the **same bin edges**).  \n",
    "- Sanity check: no overlap in indices; sizes match expected proportions.\n",
    "\n",
    "**How to reproduce**  \n",
    "Use the saved indices and bin edges; do not re-sample. If data order changes, re-index using the stored integer positions or stable IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3123f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratification by quantiles: q=5\n",
      "\n",
      "Training target distribution (same edges as stratify):\n",
      "GPA\n",
      "0    383\n",
      "1    383\n",
      "2    382\n",
      "3    382\n",
      "4    383\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test target distribution (same edges as stratify):\n",
      "GPA\n",
      "0    96\n",
      "1    95\n",
      "2    96\n",
      "3    96\n",
      "4    96\n",
      "Name: count, dtype: int64\n",
      "File saved at: C:\\Users\\Vaccari\\Desktop\\iCloudDrive\\Desktop\\ENRICO\\05_LEARNING\\University\\ToU\\Phases\\02_Calibration_Phase\\Applied_Machine_Learning\\Regression\\beyond-grades-ml-project\\data\\interim\\02_X_train_aftersplit.xlsx\n",
      "File saved at: C:\\Users\\Vaccari\\Desktop\\iCloudDrive\\Desktop\\ENRICO\\05_LEARNING\\University\\ToU\\Phases\\02_Calibration_Phase\\Applied_Machine_Learning\\Regression\\beyond-grades-ml-project\\data\\interim\\02_X_test_aftersplit.xlsx\n",
      "File saved at: C:\\Users\\Vaccari\\Desktop\\iCloudDrive\\Desktop\\ENRICO\\05_LEARNING\\University\\ToU\\Phases\\02_Calibration_Phase\\Applied_Machine_Learning\\Regression\\beyond-grades-ml-project\\data\\interim\\02_y_train_aftersplit.xlsx\n",
      "File saved at: C:\\Users\\Vaccari\\Desktop\\iCloudDrive\\Desktop\\ENRICO\\05_LEARNING\\University\\ToU\\Phases\\02_Calibration_Phase\\Applied_Machine_Learning\\Regression\\beyond-grades-ml-project\\data\\interim\\02_y_test_aftersplit.xlsx\n",
      "\n",
      "Split completed and files saved.\n"
     ]
    }
   ],
   "source": [
    "# Data splitting\n",
    "\n",
    "# Define features/target\n",
    "X = df.drop(columns=[\"GPA\"])\n",
    "y = df[\"GPA\"]\n",
    "\n",
    "# Split with safe stratification\n",
    "X_train, X_test, y_train, y_test, meta = splitting.safe_train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, max_q=5, verbose=True\n",
    ")\n",
    "\n",
    "# Check distributions using the SAME bin edges used for stratification\n",
    "if meta[\"bin_edges\"] is not None:\n",
    "    edges = meta[\"bin_edges\"]\n",
    "    print(\"\\nTraining target distribution (same edges as stratify):\")\n",
    "    print(pd.cut(y_train, bins=edges, labels=False, include_lowest=True).value_counts().sort_index())\n",
    "\n",
    "    print(\"\\nTest target distribution (same edges as stratify):\")\n",
    "    print(pd.cut(y_test, bins=edges, labels=False, include_lowest=True).value_counts().sort_index())\n",
    "else:\n",
    "    print(\"\\n(No stratification used — skipping quantile distribution check)\")\n",
    "\n",
    "# Save (Excel-friendly)\n",
    "X_train_to_save = splitting.for_excel(X_train)\n",
    "X_test_to_save  = splitting.for_excel(X_test)\n",
    "\n",
    "utils.save_dataset(X_train_to_save, \"interim/02_X_train_aftersplit.xlsx\")\n",
    "utils.save_dataset(X_test_to_save,  \"interim/02_X_test_aftersplit.xlsx\")\n",
    "utils.save_dataset(y_train.to_frame(\"GPA\"), \"interim/02_y_train_aftersplit.xlsx\")\n",
    "utils.save_dataset(y_test.to_frame(\"GPA\"),  \"interim/02_y_test_aftersplit.xlsx\")\n",
    "\n",
    "print(\"\\nSplit completed and files saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b6678b",
   "metadata": {},
   "source": [
    "### 3.2 - SAVING SPLIT METADATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39f145c",
   "metadata": {},
   "source": [
    "Below I have saved the split metadata to file (.json)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1872d1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved split metadata → data/meta/split_meta.json\n"
     ]
    }
   ],
   "source": [
    "# Save metadata about the split\n",
    "split_meta = {\n",
    "    \"method\": \"safe_train_test_split\",\n",
    "    \"params\": {\n",
    "        \"test_size\": 0.20,\n",
    "        \"random_state\": 42,\n",
    "        \"max_q\": 5,\n",
    "    },\n",
    "    \"bin_edges\": meta.get(\"bin_edges\", None),  # from your function\n",
    "    \"index\": {\n",
    "        \"train\": X_train.index.tolist(),\n",
    "        \"test\":  X_test.index.tolist(),\n",
    "    },\n",
    "    \"n_rows\": {\n",
    "        \"train\": int(len(X_train)),\n",
    "        \"test\":  int(len(X_test)),\n",
    "        \"total\": int(len(X_train) + len(X_test)),\n",
    "    },\n",
    "    \"target\": \"GPA\",\n",
    "}\n",
    "\n",
    "# Ensure all objects are JSON-safe\n",
    "safe_meta = utils.make_json_safe(split_meta)\n",
    "\n",
    "out = Path(\"../data/meta\")\n",
    "out.mkdir(parents=True, exist_ok=True)\n",
    "with open(out / \"split_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(safe_meta, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✔ Saved split metadata → data/meta/split_meta.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42bb306",
   "metadata": {},
   "source": [
    "Proper Data Splitting Implemented:\n",
    "\n",
    ">- Applied appropriate splitting strategy for my data type.\n",
    ">- Maintained (temporal/geographic/hierarchical) integrity.\n",
    ">- Validated split quality and representativeness.\n",
    ">- Documented splitting approach for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf50936",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Next Notebook - EDA\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
