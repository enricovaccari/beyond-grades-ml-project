{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ebb1ea",
   "metadata": {},
   "source": [
    "---\n",
    "# 1 - IMPORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ca5b88",
   "metadata": {},
   "source": [
    "### 1.1 - SETUP PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d91a6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports ready: pd, np, sns, plt, joblib, sklearn, etc.\n",
      "PROJECT_ROOT: /Users/enricovaccari/Desktop/ENRICO/05_LEARNING/University/ToU/Phases/02_Calibration_Phase/Applied_Machine_Learning/Regression/beyond-grades-ml-project\n"
     ]
    }
   ],
   "source": [
    "# Centralized setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Make sure PROJECT_PATH is in sys\n",
    "PROJECT_ROOT = Path.cwd().resolve().parent\n",
    "PROJECT_PATH = PROJECT_ROOT / \"src\" / \"project\"\n",
    "\n",
    "if str(PROJECT_PATH) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_PATH))\n",
    "\n",
    "# Centralized import\n",
    "from imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3796b2a7",
   "metadata": {},
   "source": [
    "Here I am loading back in the X sets (with the addition of the newly engineered features) and y sets (which have not undergone any modifications since the splitting stage)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fae91306",
   "metadata": {},
   "source": [
    "---\n",
    "# 2 - PREPROCESSING FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eac8a2",
   "metadata": {},
   "source": [
    "Before proceeding to the modeling stage, it is crucial to ensure that all features are properly prepared.  \n",
    "- **Categorical variables** (like `gender`) must be converted into numerical representations (e.g., through one-hot encoding or similar techniques).  \n",
    "- **Numerical features** (like `StudyTimeWeeky`) generally perform better when standardized to a common scale.  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "250f8381",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### 2.1 - PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98961c5",
   "metadata": {},
   "source": [
    "> **Note:**  \n",
    "Although I typically store my functions in dedicated `.py` files within the `/src` directory, the following function is essential for the next steps of this notebook. For convenience and clarity, I will define it directly here, bbut you can also find it in (../src/data/preprocessing.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de65dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(numeric_features, categorical_features, k_best=None, model=None):\n",
    "    \"\"\"\n",
    "    Preprocess:\n",
    "      - numeric: median impute + StandardScaler\n",
    "      - categorical: most_frequent impute + OneHotEncoder(ignore unknown)\n",
    "    Then (optional) SelectKBest(f_regression, k=k_best), then model.\n",
    "    CV-safe: tutto viene rifittato per ogni fold.\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        model = LinearRegression()\n",
    "\n",
    "    # Define transformers for preprocessing\n",
    "    numerical_transformer = StandardScaler()\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')  # One-hot encode region\n",
    "    \n",
    "    # Define imputers \n",
    "    numerical_imputer = SimpleImputer(strategy='median')  # Impute with median as numeric features are not normally distributed\n",
    "    categorical_imputer = SimpleImputer(strategy='most_frequent')  # Impute with most frequent\n",
    "\n",
    "    # Build preprocessor\n",
    "    num_pipe = Pipeline([\n",
    "        (\"imputer\", numerical_imputer),\n",
    "        (\"scaler\", numerical_transformer),\n",
    "    ])\n",
    "    cat_pipe = Pipeline([\n",
    "        (\"imputer\", categorical_imputer),\n",
    "        (\"ohe\", categorical_transformer),\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", num_pipe, numeric_features),\n",
    "        (\"cat\", cat_pipe, categorical_features),\n",
    "    ])\n",
    "\n",
    "    selector = SelectKBest(score_func=f_regression, k=k_best) if k_best is not None else \"passthrough\"\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"select\", selector),\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecbc7ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names_after_preprocess(pipe, numeric_features, categorical_features):\n",
    "    \"\"\"\n",
    "    Column names after preprocessing (original numeric + expanded OHE categorical).\n",
    "    Call AFTER pipe.fit(...).\n",
    "    \"\"\"\n",
    "    pre = pipe.named_steps[\"preprocessor\"]\n",
    "    ohe = pre.named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "    cat_names = ohe.get_feature_names_out(categorical_features)\n",
    "    return list(numeric_features) + list(cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c4a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_features(pipe, numeric_features, categorical_features):\n",
    "    \"\"\"\n",
    "    Returns (all_names, scores, mask, selected_names) after fitting.\n",
    "    If k_best=None, mask is all True and scores are NaN.\n",
    "    \"\"\"\n",
    "    all_names = get_feature_names_after_preprocess(pipe, numeric_features, categorical_features)\n",
    "    selector = pipe.named_steps.get(\"select\", None)\n",
    "\n",
    "    if selector in (None, \"passthrough\"):\n",
    "        scores = np.full(len(all_names), np.nan)\n",
    "        mask = np.ones(len(all_names), dtype=bool)\n",
    "        selected_names = all_names\n",
    "        return all_names, scores, mask, selected_names\n",
    "\n",
    "    scores = selector.scores_\n",
    "    mask = selector.get_support()\n",
    "    selected_names = [n for n, keep in zip(all_names, mask) if keep]\n",
    "    return all_names, scores, mask, selected_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6227ecd",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "**How I Built My Preprocessing & Modeling Pipeline**\n",
    "\n",
    "My pipeline is designed to ensure robust, reproducible, and leakage-free preprocessing and modeling. Hereâ€™s how it works and why:\n",
    "\n",
    "**Pipeline Construction**\n",
    "\n",
    "- **Numeric features** (`numeric_features`):  \n",
    "    - Imputed with the median (to handle missing values robustly).\n",
    "    - Standardized using `StandardScaler` (zero mean, unit variance).\n",
    "\n",
    "- **Categorical features** (`categorical_features`):  \n",
    "    - Imputed with the most frequent value.\n",
    "    - One-hot encoded (`OneHotEncoder(handle_unknown='ignore')`).\n",
    "\n",
    "- **Feature selection**:  \n",
    "    - Optionally, I use `SelectKBest(f_regression, k=k_best)` to keep only the most predictive features.\n",
    "    - I can also force-keep domain-relevant features (e.g., `EngagementIndex`) even if not selected by univariate tests.\n",
    "\n",
    "- **Model**:  \n",
    "    - The pipeline can end with any estimator (e.g., `LinearRegression`, `Ridge`, etc.).\n",
    "\n",
    "All these steps are combined using `Pipeline` and `ColumnTransformer` for clean, modular, and scikit-learn-compatible workflows.\n",
    "\n",
    "### My Strategy: Cross-Validation & Final Model\n",
    "\n",
    "#### ðŸ”„ What does cross-validation do?\n",
    "\n",
    "- Splits the training set into folds (e.g., 5 parts).\n",
    "- For each fold:\n",
    "    - Fits preprocessing, feature selection, and model on 4/5 of the data.\n",
    "    - Evaluates on the remaining 1/5.\n",
    "- Returns an average metric (e.g., RMSE, RÂ²) â€” this estimates how well the whole process generalizes.\n",
    "- **Note:** Each fold may select slightly different features and fit a slightly different model.\n",
    "\n",
    "#### ðŸš© Why refit on the full training set?\n",
    "\n",
    "- Once Iâ€™ve chosen the best pipeline and parameters (e.g., `k_best=12`, `Ridge(alpha=1.0)`), I refit the entire pipeline on 100% of the training data.\n",
    "- This uses all available information, making the final model as robust as possible.\n",
    "- Feature selection is now based on the whole training set, giving a definitive list of features.\n",
    "- This final model is what I apply to the hold-out test set (or future data).\n",
    "\n",
    "#### âœ… Standard Workflow\n",
    "\n",
    "1. **Cross-validation**\n",
    "     - Choose hyperparameters, model, number of features.\n",
    "     - Get a realistic estimate of performance.\n",
    "\n",
    "2. **Refit on full training set**\n",
    "     - Build the final, unique model with those parameters.\n",
    "     - Get the definitive feature list.\n",
    "\n",
    "3. **Final test**\n",
    "     - Evaluate this model on the (never-seen) test set (which will need scaling/transformation as well).\n",
    "\n",
    "#### ðŸŒ± In short\n",
    "\n",
    "Refitting on the full training set:\n",
    "- Maximizes use of available data â†’ more robust model.\n",
    "- Freezes the final pipeline (selected features, scaling, encoding, parameters).\n",
    "- Prepares the model for production or final test evaluation.\n",
    "\n",
    "This approach ensures that my modeling process is both statistically sound and ready for real-world application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (v3.10.5:f377153967, Jun  6 2022, 12:36:10) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
